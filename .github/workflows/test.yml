name: Test
on:
  workflow_dispatch:
    inputs:
      border_score:
        type: integer
        default: 90
        required: true
        description: 'Border score for evaluation'
  push:
    inputs:
      border_score:
        type: integer
        default: 90
        required: true
        description: 'Border score for evaluation'
jobs:
  sample:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Run test_main.py
        run: python -u src_old/test_*.py
  evaluation_score:
    runs-on: ubuntu-latest
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run and get average score
        id: get_score
        run: |
          score=$(python -u src/use_dataset.py)
          echo "score=$score" >> $GITHUB_OUTPUT

      - env:
          RESULT: ${{ steps.get_score.outputs.score }}
        run: echo "${RESULT}"

      - name: show border score
        run: echo "${{ inputs.border_score }}"